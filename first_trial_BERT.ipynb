{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ruecker/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import utils\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "PRE_TRAINED_MODEL_NAME = 'bert-base-german-cased' # 'distilbert-base-german-cased'\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitely activated but `max_length` is provided a specific value, please use `truncation=True` to explicitely truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Das', 'hier', 'ist', 'ein', 'deutscher', 'Beispiel', '##text', '.', 'Und', 'einen', 'zweiten', 'müssen', 'wir', 'auch', 'noch', 'haben', '.']\n",
      "[295, 702, 127, 39, 2433, 2249, 8859, 26914, 1356, 303, 1909, 1475, 232, 194, 357, 474, 26914]\n",
      "[3, 295, 702, 127, 39, 2433, 2249, 8859, 26914, 1356, 303, 1909, 1475, 232, 194, 357, 474, 26914, 4]\n",
      "---\n",
      "{'input_ids': [3, 295, 702, 127, 39, 2433, 2249, 8859, 26914, 4], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    }
   ],
   "source": [
    "sample_text = \"Das hier ist ein deutscher Beispieltext. Und einen zweiten müssen wir auch noch haben.\"\n",
    "tokens = tokenizer.tokenize(sample_text) # just tokenizes\n",
    "token_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "ids = tokenizer.encode(sample_text) # already adds special tokens\n",
    "encoded_plus = tokenizer.encode_plus(sample_text,\n",
    "                                     max_length = 10,\n",
    "                                     return_token_type_ids=False,\n",
    "                                     pad_to_max_length=True,\n",
    "                                     return_attention_mask=True,)\n",
    "\n",
    "print(tokens)\n",
    "print(token_ids)\n",
    "print(ids)\n",
    "print(\"---\")\n",
    "print(encoded_plus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer.get_vocab() # shows tokenizer vocab (subwords!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('[SEP]', 4, '[CLS]', 3, '[PAD]', 0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token, tokenizer.sep_token_id, tokenizer.cls_token, tokenizer.cls_token_id, tokenizer.pad_token, tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ROOT = Path('/Volumes/INWT/Daten_NLP/') # local (Laptop)\n",
    "ROOT = Path('/home/ruecker/data/Daten_INWT/') # JULIE-Server\n",
    "\n",
    "DATA = ROOT / '200707_aachener_zeitung_modified.csv' # text is already minimal preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class INWT_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, target, text_base, tokenizer, max_len):\n",
    "        self.df = df\n",
    "        self.text_base = text_base\n",
    "        self.target = target\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        text = str(self.df.loc[item, self.text_base])\n",
    "        target = np.array(self.df.loc[item, self.target])\n",
    "\n",
    "        # hier einfach encode() nehmen? brauche ich die attention_mask etc?\n",
    "        encoding = self.tokenizer.encode_plus(text,\n",
    "                                              max_length=self.max_len,\n",
    "                                              truncation=True,\n",
    "                                              return_token_type_ids=False,\n",
    "                                              pad_to_max_length=True,\n",
    "                                              return_attention_mask=True,\n",
    "                                              return_tensors='pt',\n",
    "                                              )\n",
    "\n",
    "        return {'text': text,\n",
    "                'input_ids': encoding['input_ids'].flatten(),\n",
    "                'attention_mask': encoding['attention_mask'].flatten(),\n",
    "                'target': torch.tensor(target, dtype=torch.float).unsqueeze(dim=-1) # unsqueezing so shape (batch_size,1)\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleId</th>\n",
       "      <th>pageviews</th>\n",
       "      <th>entrances</th>\n",
       "      <th>exits</th>\n",
       "      <th>bounces</th>\n",
       "      <th>timeOnPage</th>\n",
       "      <th>conversions</th>\n",
       "      <th>avgTimeOnPage</th>\n",
       "      <th>stickiness</th>\n",
       "      <th>entranceRate</th>\n",
       "      <th>...</th>\n",
       "      <th>nr_tokens</th>\n",
       "      <th>mean_token_length</th>\n",
       "      <th>nr_tokens_teaser</th>\n",
       "      <th>nr_tokens_titelH1</th>\n",
       "      <th>nr_char</th>\n",
       "      <th>nr_sentences</th>\n",
       "      <th>mean_sentence_length</th>\n",
       "      <th>avgTimeOnPage/wordcount</th>\n",
       "      <th>avgTimeOnPage/nr_char</th>\n",
       "      <th>pageviews-exits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>48620281</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>7</td>\n",
       "      <td>1012</td>\n",
       "      <td></td>\n",
       "      <td>112.444444</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>796</td>\n",
       "      <td>5.359296</td>\n",
       "      <td>29</td>\n",
       "      <td>9</td>\n",
       "      <td>5148</td>\n",
       "      <td>52.0</td>\n",
       "      <td>15.307692</td>\n",
       "      <td>0.146222</td>\n",
       "      <td>0.021842</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>48620381</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>1484</td>\n",
       "      <td></td>\n",
       "      <td>185.500000</td>\n",
       "      <td>42.105263</td>\n",
       "      <td>31.578947</td>\n",
       "      <td>...</td>\n",
       "      <td>452</td>\n",
       "      <td>5.938053</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>3182</td>\n",
       "      <td>28.0</td>\n",
       "      <td>16.142857</td>\n",
       "      <td>0.420635</td>\n",
       "      <td>0.058297</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48622639</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>396</td>\n",
       "      <td>5.848485</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>2776</td>\n",
       "      <td>26.0</td>\n",
       "      <td>15.230769</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>48623085</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>974</td>\n",
       "      <td></td>\n",
       "      <td>81.166667</td>\n",
       "      <td>37.500000</td>\n",
       "      <td>28.125000</td>\n",
       "      <td>...</td>\n",
       "      <td>367</td>\n",
       "      <td>5.594005</td>\n",
       "      <td>30</td>\n",
       "      <td>7</td>\n",
       "      <td>2442</td>\n",
       "      <td>23.0</td>\n",
       "      <td>15.956522</td>\n",
       "      <td>0.235266</td>\n",
       "      <td>0.033238</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48623259</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>3797</td>\n",
       "      <td></td>\n",
       "      <td>223.352941</td>\n",
       "      <td>70.833333</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>183</td>\n",
       "      <td>5.622951</td>\n",
       "      <td>22</td>\n",
       "      <td>8</td>\n",
       "      <td>1243</td>\n",
       "      <td>8.0</td>\n",
       "      <td>22.875000</td>\n",
       "      <td>1.227214</td>\n",
       "      <td>0.179689</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   articleId  pageviews  entrances  exits  bounces  timeOnPage conversions  \\\n",
       "0   48620281         21          7     12        7        1012               \n",
       "1   48620381         19          6     11        5        1484               \n",
       "2   48622639          2          2      2        2           0               \n",
       "3   48623085         32          9     20        9         974               \n",
       "4   48623259         24          2      7        2        3797               \n",
       "\n",
       "   avgTimeOnPage  stickiness  entranceRate  ...  nr_tokens mean_token_length  \\\n",
       "0     112.444444   42.857143     33.333333  ...        796          5.359296   \n",
       "1     185.500000   42.105263     31.578947  ...        452          5.938053   \n",
       "2       0.000000    0.000000    100.000000  ...        396          5.848485   \n",
       "3      81.166667   37.500000     28.125000  ...        367          5.594005   \n",
       "4     223.352941   70.833333      8.333333  ...        183          5.622951   \n",
       "\n",
       "  nr_tokens_teaser nr_tokens_titelH1 nr_char nr_sentences  \\\n",
       "0               29                 9    5148         52.0   \n",
       "1               33                 8    3182         28.0   \n",
       "2               30                 7    2776         26.0   \n",
       "3               30                 7    2442         23.0   \n",
       "4               22                 8    1243          8.0   \n",
       "\n",
       "  mean_sentence_length avgTimeOnPage/wordcount avgTimeOnPage/nr_char  \\\n",
       "0            15.307692                0.146222              0.021842   \n",
       "1            16.142857                0.420635              0.058297   \n",
       "2            15.230769                0.000000              0.000000   \n",
       "3            15.956522                0.235266              0.033238   \n",
       "4            22.875000                1.227214              0.179689   \n",
       "\n",
       "  pageviews-exits  \n",
       "0               9  \n",
       "1               8  \n",
       "2               0  \n",
       "3              12  \n",
       "4              17  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_raw = pd.read_csv(DATA)\n",
    "df_raw = df_raw.fillna('') # replacing Nan with emtpy string\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "891\n"
     ]
    }
   ],
   "source": [
    "# just take articles where ...\n",
    "#df = df_raw.loc[(df_raw['pageviews'] >= 5)]\n",
    "\n",
    "#df = df_raw.loc[(df_raw['pageviews'] >= 5) &\n",
    "#                (df_raw['avgTimeOnPage/wordcount'] <= 5) &\n",
    "#                (df_raw['avgTimeOnPage/wordcount'] >= 0.1)]\n",
    "\n",
    "# or all...\n",
    "df = df_raw\n",
    "\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(712, 41) (89, 41) (90, 41)\n"
     ]
    }
   ],
   "source": [
    "#creating train, dev, test\n",
    "RANDOM_SEED = 123\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED, shuffle=True)\n",
    "df_dev, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED, shuffle=True)\n",
    "df_train.reset_index(drop=True, inplace=True) # so that index starts with 0 again\n",
    "df_dev.reset_index(drop=True, inplace=True)\n",
    "df_test.reset_index(drop=True, inplace=True)\n",
    "print(df_train.shape, df_dev.shape, df_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleId</th>\n",
       "      <th>pageviews</th>\n",
       "      <th>entrances</th>\n",
       "      <th>exits</th>\n",
       "      <th>bounces</th>\n",
       "      <th>timeOnPage</th>\n",
       "      <th>conversions</th>\n",
       "      <th>avgTimeOnPage</th>\n",
       "      <th>stickiness</th>\n",
       "      <th>entranceRate</th>\n",
       "      <th>...</th>\n",
       "      <th>nr_tokens</th>\n",
       "      <th>mean_token_length</th>\n",
       "      <th>nr_tokens_teaser</th>\n",
       "      <th>nr_tokens_titelH1</th>\n",
       "      <th>nr_char</th>\n",
       "      <th>nr_sentences</th>\n",
       "      <th>mean_sentence_length</th>\n",
       "      <th>avgTimeOnPage/wordcount</th>\n",
       "      <th>avgTimeOnPage/nr_char</th>\n",
       "      <th>pageviews-exits</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49583837</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>3680</td>\n",
       "      <td></td>\n",
       "      <td>262.857143</td>\n",
       "      <td>50.0</td>\n",
       "      <td>28.571429</td>\n",
       "      <td>...</td>\n",
       "      <td>655</td>\n",
       "      <td>6.097710</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>4710</td>\n",
       "      <td>40.0</td>\n",
       "      <td>16.375000</td>\n",
       "      <td>0.417234</td>\n",
       "      <td>0.055808</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51204297</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>417</td>\n",
       "      <td></td>\n",
       "      <td>139.000000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>77</td>\n",
       "      <td>6.363636</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>579</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.833333</td>\n",
       "      <td>1.737500</td>\n",
       "      <td>0.240069</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49230331</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>171</td>\n",
       "      <td></td>\n",
       "      <td>57.000000</td>\n",
       "      <td>75.0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>124</td>\n",
       "      <td>6.201613</td>\n",
       "      <td>24</td>\n",
       "      <td>6</td>\n",
       "      <td>910</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.400000</td>\n",
       "      <td>0.448819</td>\n",
       "      <td>0.062637</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>49825661</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1501</td>\n",
       "      <td></td>\n",
       "      <td>500.333333</td>\n",
       "      <td>60.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>178</td>\n",
       "      <td>5.528090</td>\n",
       "      <td>28</td>\n",
       "      <td>8</td>\n",
       "      <td>1180</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.800000</td>\n",
       "      <td>2.842803</td>\n",
       "      <td>0.424011</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>48897105</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td></td>\n",
       "      <td>41.333333</td>\n",
       "      <td>60.0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>146</td>\n",
       "      <td>6.410959</td>\n",
       "      <td>25</td>\n",
       "      <td>7</td>\n",
       "      <td>1104</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.600000</td>\n",
       "      <td>0.277405</td>\n",
       "      <td>0.037440</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   articleId  pageviews  entrances  exits  bounces  timeOnPage conversions  \\\n",
       "0   49583837         28          8     14        7        3680               \n",
       "1   51204297          4          0      1        0         417               \n",
       "2   49230331          4          1      1        1         171               \n",
       "3   49825661          5          2      2        2        1501               \n",
       "4   48897105          5          2      2        2         124               \n",
       "\n",
       "   avgTimeOnPage  stickiness  entranceRate  ...  nr_tokens mean_token_length  \\\n",
       "0     262.857143        50.0     28.571429  ...        655          6.097710   \n",
       "1     139.000000        75.0      0.000000  ...         77          6.363636   \n",
       "2      57.000000        75.0     25.000000  ...        124          6.201613   \n",
       "3     500.333333        60.0     40.000000  ...        178          5.528090   \n",
       "4      41.333333        60.0     40.000000  ...        146          6.410959   \n",
       "\n",
       "  nr_tokens_teaser nr_tokens_titelH1 nr_char nr_sentences  \\\n",
       "0               27                 7    4710         40.0   \n",
       "1               24                 6     579          6.0   \n",
       "2               24                 6     910         10.0   \n",
       "3               28                 8    1180         10.0   \n",
       "4               25                 7    1104         10.0   \n",
       "\n",
       "  mean_sentence_length avgTimeOnPage/wordcount avgTimeOnPage/nr_char  \\\n",
       "0            16.375000                0.417234              0.055808   \n",
       "1            12.833333                1.737500              0.240069   \n",
       "2            12.400000                0.448819              0.062637   \n",
       "3            17.800000                2.842803              0.424011   \n",
       "4            14.600000                0.277405              0.037440   \n",
       "\n",
       "  pageviews-exits  \n",
       "0              14  \n",
       "1               3  \n",
       "2               3  \n",
       "3               3  \n",
       "4               3  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_DataLoaders(target, text_base, tokenizer, max_len, batch_size):\n",
    "    # creating DataSets\n",
    "    ds_train = INWT_Dataset(df=df_train,\n",
    "                  target = target,\n",
    "                  text_base = text_base,\n",
    "                  tokenizer=tokenizer,\n",
    "                  max_len = max_len)\n",
    "    ds_dev = INWT_Dataset(df=df_dev,\n",
    "                  target = target,\n",
    "                  text_base = text_base,\n",
    "                  tokenizer=tokenizer,\n",
    "                  max_len = max_len)\n",
    "    ds_test = INWT_Dataset(df=df_test,\n",
    "                  target = target,\n",
    "                  text_base = text_base,\n",
    "                  tokenizer=tokenizer,\n",
    "                  max_len = max_len)\n",
    "    \n",
    "    # creating DataLoaders\n",
    "    dl_train = DataLoader(ds_train, batch_size=batch_size, num_workers=4, shuffle=True)\n",
    "    dl_dev = DataLoader(ds_dev, batch_size=batch_size, num_workers=4)\n",
    "    dl_test = DataLoader(ds_test, batch_size=batch_size, num_workers=4)\n",
    "    \n",
    "    return dl_train, dl_dev, dl_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train, dl_dev, dl_test = create_DataLoaders(target = 'avgTimeOnPage/wordcount',\n",
    "                                               text_base = 'text_preprocessed', # 'titelH1',\n",
    "                                               tokenizer = tokenizer, \n",
    "                                               max_len = 100,            # change depending on used text_base!\n",
    "                                               batch_size = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['text', 'input_ids', 'attention_mask', 'target'])\n",
      "torch.Size([8, 100])\n",
      "torch.Size([8, 100])\n",
      "torch.Size([8, 1])\n"
     ]
    }
   ],
   "source": [
    "# have a look at one batch\n",
    "data = next(iter(dl_train))\n",
    "print(data.keys())\n",
    "input_ids = data['input_ids']\n",
    "#print(input_ids)\n",
    "print(input_ids.shape)\n",
    "attention_mask = data['attention_mask']\n",
    "#print(attention_mask)\n",
    "print(attention_mask.shape)\n",
    "print(data['target'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# das ist umständlich (und auch falsch), ich habe stattdessen bereits BertForSequenceClassification genommen\n",
    "# https://huggingface.co/transformers/v2.2.0/model_doc/bert.html#transformers.BertForSequenceClassification\n",
    "\n",
    "#class Bert_regression(nn.Module):\n",
    "#    \n",
    "#    def __init__(self, n_outputs): # maybe train pageviews and timeOnPage simultaneously?\n",
    "#        super(Bert_regression, self).__init__()\n",
    "#        self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME)\n",
    "#        self.drop = nn.Dropout(p=0.3)\n",
    "#        self.out = nn.Linear(self.bert.config.hidden_size, n_outputs)\n",
    "#\n",
    "#    def forward(self, input_ids, attention_mask):\n",
    "#        _, pooled_output = self.bert(input_ids=input_ids,           # das hier ist glaube ich nicht sinnvoll bei mir\n",
    "#                                     attention_mask=attention_mask)\n",
    "#        output = self.drop(pooled_output)        \n",
    "#        return self.out(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = Bert_regression(n_outputs = 1)\n",
    "#model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(PRE_TRAINED_MODEL_NAME,\n",
    "                                                      num_labels = 1, # turns \"classification\" into regression?\n",
    "                                                      output_attentions = False,\n",
    "                                                      output_hidden_states = False,\n",
    "                                                      )\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.4910],\n",
       "         [0.1137],\n",
       "         [0.2864],\n",
       "         [0.0126],\n",
       "         [0.0241],\n",
       "         [0.2552],\n",
       "         [0.1826],\n",
       "         [0.2770]], device='cuda:0', grad_fn=<AddmmBackward>),)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try ut with one batch (model is not trained yet so nothing exciting to be expected)\n",
    "model(input_ids.to(device), attention_mask.to(device)) # semms good!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
    "loss_fn = nn.MSELoss()  # mean squared loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "training\n",
      "Mean train loss: 0.2738990727812052\n",
      "evaluating\n",
      "Mean eval loss: 0.8107139143206344\n",
      "Epoch 1\n",
      "training\n",
      "Mean train loss: 0.2092793703162938\n",
      "evaluating\n",
      "Mean eval loss: 0.8263743265997618\n",
      "Epoch 2\n",
      "training\n",
      "Mean train loss: 0.14616796801264367\n",
      "evaluating\n",
      "Mean eval loss: 0.8370372052304447\n",
      "Epoch 3\n",
      "training\n",
      "Mean train loss: 0.10060928159215476\n",
      "evaluating\n",
      "Mean eval loss: 0.8128398333986601\n",
      "Epoch 4\n",
      "training\n",
      "Mean train loss: 0.059061058796942234\n",
      "evaluating\n",
      "Mean eval loss: 0.8307045791320604\n",
      "Epoch 5\n",
      "training\n",
      "Mean train loss: 0.04686081623972467\n",
      "evaluating\n",
      "Mean eval loss: 0.8392508854934325\n",
      "Epoch 6\n",
      "training\n",
      "-Batch 61\r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process Process-54:\n",
      "Process Process-53:\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/multiprocessing/process.py\", line 300, in _bootstrap\n",
      "    util._exit_function()\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/multiprocessing/util.py\", line 337, in _exit_function\n",
      "    _run_finalizers()\n",
      "KeyboardInterrupt\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/multiprocessing/util.py\", line 277, in _run_finalizers\n",
      "    finalizer()\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/multiprocessing/util.py\", line 201, in __call__\n",
      "    res = self._callback(*self._args, **self._kwargs)\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/multiprocessing/queues.py\", line 192, in _finalize_join\n",
      "    thread.join()\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/threading.py\", line 1044, in join\n",
      "    self._wait_for_tstate_lock()\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/threading.py\", line 1060, in _wait_for_tstate_lock\n",
      "    elif lock.acquire(block, timeout):\n",
      "KeyboardInterrupt\n",
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f4efc8ef950>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 926, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/site-packages/torch/utils/data/dataloader.py\", line 906, in _shutdown_workers\n",
      "    w.join()\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/multiprocessing/process.py\", line 140, in join\n",
      "    res = self._popen.wait(timeout)\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/multiprocessing/popen_fork.py\", line 48, in wait\n",
      "    return self.poll(os.WNOHANG if timeout == 0.0 else 0)\n",
      "  File \"/home/ruecker/miniconda3/envs/GPU/lib/python3.7/multiprocessing/popen_fork.py\", line 28, in poll\n",
      "    pid, sts = os.waitpid(self.pid, flag)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7697169de1d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m#print(outputs.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mtrain_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/GPU/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/GPU/lib/python3.7/site-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/GPU/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[0;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2202\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2203\u001b[0m         \u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2204\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2205\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(\"Epoch\", epoch)\n",
    "    \n",
    "    ### TRAINING on train\n",
    "    print(\"training\")\n",
    "    model = model.train()\n",
    "    train_losses = []\n",
    "    \n",
    "    for nr, d in enumerate(dl_train):\n",
    "        print(\"-Batch\", nr, end='\\r')\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"target\"].to(device)\n",
    "        #print(targets.shape)    \n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)[0] # stimmt das so? ist [0] die logits?\n",
    "        #print(outputs.shape)\n",
    "        \n",
    "        loss = loss_fn(outputs, targets)\n",
    "        train_losses.append(loss.item())\n",
    "        loss.backward()\n",
    "\n",
    "        #nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        #print(np.mean(train_losses))\n",
    "    print(\"Mean train loss:\", np.mean(train_losses))\n",
    "    \n",
    "    ### EVALUATING on dev\n",
    "    print(\"evaluating\")\n",
    "    model = model.eval()\n",
    "    eval_losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for nr, d in enumerate(dl_dev):\n",
    "            print(\"-Batch\", nr, end='\\r')\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"target\"].to(device)\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)[0] # stimmt das so?\n",
    "        \n",
    "            loss = loss_fn(outputs, targets)\n",
    "            eval_losses.append(loss.item())\n",
    "            #print(np.mean(eval_losses))\n",
    "        print(\"Mean eval loss:\", np.mean(eval_losses))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## predict dev set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, dl_dev_oneBatch, _ = create_DataLoaders(target = 'avgTimeOnPage/wordcount',\n",
    "                                               text_base = 'text_preprocessed', # 'teaser'\n",
    "                                               tokenizer = tokenizer, \n",
    "                                               max_len = 100,            # change depending on used text_base!\n",
    "                                               batch_size = 89) # for now: just one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5329,  0.2562,  0.4639,  0.3975,  0.3378,  0.1366,  0.3866,  0.5034,\n",
      "         0.4795,  0.3761,  0.3445,  0.4251,  0.8253,  0.2645,  0.3172,  0.6630,\n",
      "         0.3116,  0.1757,  0.4417,  0.0116,  0.5449,  0.9076,  0.1101,  0.7867,\n",
      "         1.0569,  0.3484,  0.5437,  0.1672,  0.3955,  0.1168,  0.7323,  0.6364,\n",
      "         0.1067,  0.4060,  0.7389,  0.3821,  0.5545,  0.4256,  0.4132,  1.2090,\n",
      "         0.2423,  0.3605, -0.0208,  0.1978,  0.2604,  0.3660,  0.2688,  0.3128,\n",
      "         0.3575,  0.2891,  0.1810,  0.1984,  0.1762,  0.3948,  0.4105,  0.7182,\n",
      "         0.3595,  0.6303,  0.7492,  0.5521,  0.5746,  0.3578, -0.0190,  0.9274,\n",
      "         0.2742,  0.1476,  0.2406,  0.3628,  0.4523,  0.3634,  0.4850,  0.3599,\n",
      "         0.5240,  0.1677,  0.9379,  0.4969,  0.4776,  0.4500,  0.3288,  0.3787,\n",
      "         0.3845,  0.1362,  0.2795,  0.4424,  0.5441,  0.2259,  0.1552,  0.3783,\n",
      "         0.1311])\n",
      "tensor([0.4269, 0.2815, 0.0705, 0.0231, 0.0000, 0.2753, 6.7727, 0.4919, 0.1215,\n",
      "        0.2277, 0.0000, 0.1750, 0.1892, 0.2461, 0.0440, 0.4887, 0.1094, 0.7061,\n",
      "        0.3923, 0.5664, 3.0380, 0.2893, 1.1059, 0.7952, 0.8124, 0.2480, 0.3555,\n",
      "        0.4714, 0.3045, 0.0596, 0.2931, 0.3485, 0.2860, 0.3199, 0.4694, 0.2368,\n",
      "        0.3005, 0.0953, 0.3710, 0.1707, 0.0613, 0.0622, 0.0928, 0.0542, 0.2762,\n",
      "        0.1105, 0.1634, 0.1959, 0.1476, 0.0855, 0.1319, 1.8150, 0.3358, 0.5921,\n",
      "        1.6402, 0.4272, 0.2233, 0.1738, 0.1885, 0.8457, 0.1085, 0.6625, 0.0000,\n",
      "        2.4377, 0.8317, 0.1061, 0.2984, 0.1166, 4.4294, 0.7532, 0.0422, 0.0000,\n",
      "        0.2093, 0.1714, 0.5188, 0.4648, 0.4714, 0.1350, 0.1443, 0.1632, 0.0000,\n",
      "        0.1401, 0.2148, 0.5542, 0.0000, 0.2662, 0.0425, 0.1992, 0.2637])\n",
      "(0.11007443552805618, 0.30447481581857955)\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for d in dl_dev_oneBatch:\n",
    "        pred_dev = model(input_ids=d[\"input_ids\"].to(device), attention_mask=d[\"attention_mask\"].to(device))[0] # just the logits?\n",
    "        y_dev = d[\"target\"].to(device)\n",
    "        \n",
    "        pred_dev = pred_dev.squeeze().cpu()\n",
    "        y_dev = y_dev.squeeze().cpu()\n",
    "        print(pred_dev)\n",
    "        print(y_dev)\n",
    "        print(st.pearsonr(pred_dev, y_dev))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kommentare:\n",
    "* ist jetzt auf GPU\n",
    "* Overfitting! Dropout? zu wenig Daten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
