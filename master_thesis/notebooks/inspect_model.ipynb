{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from master_thesis.src import utils, models, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.FFN_BERT_pretrained(n_outputs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FFN_BERT_pretrained(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (fc_bert): Linear(in_features=768, out_features=256, bias=True)\n",
       "  (LReLU): LeakyReLU(negative_slope=0.01)\n",
       "  (dropout): Dropout(p=0.3, inplace=False)\n",
       "  (baseline_in_FFN_BERT): baseline_in_FFN_BERT(\n",
       "    (LReLU): LeakyReLU(negative_slope=0.01)\n",
       "    (dropout): Dropout(p=0.3, inplace=False)\n",
       "    (publisher_embs): Embedding(5, 100)\n",
       "    (fc1): Linear(in_features=101, out_features=256, bias=True)\n",
       "    (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
       "    (out): Linear(in_features=64, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "\t torch.Size([30000, 768])\n",
      "bert.embeddings.position_embeddings.weight\n",
      "\t torch.Size([512, 768])\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "\t torch.Size([2, 768])\n",
      "bert.embeddings.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.embeddings.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "\t torch.Size([3072, 768])\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "\t torch.Size([3072])\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "\t torch.Size([768, 3072])\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "\t torch.Size([3072, 768])\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "\t torch.Size([3072])\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "\t torch.Size([768, 3072])\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "\t torch.Size([3072, 768])\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "\t torch.Size([3072])\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "\t torch.Size([768, 3072])\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "\t torch.Size([3072, 768])\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "\t torch.Size([3072])\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "\t torch.Size([768, 3072])\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "\t torch.Size([3072, 768])\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "\t torch.Size([3072])\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "\t torch.Size([768, 3072])\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "\t torch.Size([3072, 768])\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "\t torch.Size([3072])\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "\t torch.Size([768, 3072])\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "\t torch.Size([3072, 768])\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "\t torch.Size([3072])\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "\t torch.Size([768, 3072])\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "\t torch.Size([3072, 768])\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "\t torch.Size([3072])\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "\t torch.Size([768, 3072])\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "\t torch.Size([3072, 768])\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "\t torch.Size([3072])\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "\t torch.Size([768, 3072])\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "\t torch.Size([3072, 768])\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "\t torch.Size([3072])\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "\t torch.Size([768, 3072])\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "\t torch.Size([3072, 768])\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "\t torch.Size([3072])\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "\t torch.Size([768, 3072])\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "\t torch.Size([3072, 768])\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "\t torch.Size([3072])\n",
      "bert.encoder.layer.11.output.dense.weight\n",
      "\t torch.Size([768, 3072])\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "\t torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "\t torch.Size([768])\n",
      "bert.pooler.dense.weight\n",
      "\t torch.Size([768, 768])\n",
      "bert.pooler.dense.bias\n",
      "\t torch.Size([768])\n",
      "fc_bert.weight\n",
      "\t torch.Size([256, 768])\n",
      "fc_bert.bias\n",
      "\t torch.Size([256])\n",
      "baseline_in_FFN_BERT.publisher_embs.weight\n",
      "\t torch.Size([5, 100])\n",
      "baseline_in_FFN_BERT.fc1.weight\n",
      "\t torch.Size([256, 101])\n",
      "baseline_in_FFN_BERT.fc1.bias\n",
      "\t torch.Size([256])\n",
      "baseline_in_FFN_BERT.fc2.weight\n",
      "\t torch.Size([128, 256])\n",
      "baseline_in_FFN_BERT.fc2.bias\n",
      "\t torch.Size([128])\n",
      "baseline_in_FFN_BERT.fc3.weight\n",
      "\t torch.Size([64, 128])\n",
      "baseline_in_FFN_BERT.fc3.bias\n",
      "\t torch.Size([64])\n",
      "baseline_in_FFN_BERT.out.weight\n",
      "\t torch.Size([1, 64])\n",
      "baseline_in_FFN_BERT.out.bias\n",
      "\t torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(name)\n",
    "    print(\"\\t\", param.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading one checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "identifier = 'FFNBERT_pretrained_FIXLEN300_MINLENNone_START0_EP50_BS8_LR1e-05_avgTimeOnPage'\n",
    "PATH = utils.OUTPUT / 'saved_models' / f'{identifier}'\n",
    "model.load_state_dict(torch.load(PATH, map_location=torch.device('cpu')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bert.embeddings.word_embeddings.weight\n",
      "torch.Size([30000, 768])\n",
      "bert.embeddings.position_embeddings.weight\n",
      "torch.Size([512, 768])\n",
      "bert.embeddings.token_type_embeddings.weight\n",
      "torch.Size([2, 768])\n",
      "bert.embeddings.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.embeddings.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.0.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.0.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.0.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "bert.encoder.layer.0.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "bert.encoder.layer.0.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "bert.encoder.layer.0.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.0.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.1.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.1.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.1.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "bert.encoder.layer.1.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "bert.encoder.layer.1.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "bert.encoder.layer.1.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.1.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.2.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.2.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.2.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "bert.encoder.layer.2.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "bert.encoder.layer.2.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "bert.encoder.layer.2.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.2.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.3.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.3.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.3.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "bert.encoder.layer.3.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "bert.encoder.layer.3.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "bert.encoder.layer.3.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.3.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.4.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.4.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.4.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "bert.encoder.layer.4.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "bert.encoder.layer.4.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "bert.encoder.layer.4.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.4.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.5.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.5.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.5.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "bert.encoder.layer.5.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "bert.encoder.layer.5.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "bert.encoder.layer.5.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.5.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.6.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.6.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.6.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "bert.encoder.layer.6.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "bert.encoder.layer.6.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "bert.encoder.layer.6.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.6.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.7.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.7.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.7.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "bert.encoder.layer.7.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "bert.encoder.layer.7.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "bert.encoder.layer.7.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.7.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.8.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.8.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.8.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "bert.encoder.layer.8.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "bert.encoder.layer.8.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "bert.encoder.layer.8.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.8.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.9.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.9.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.9.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "bert.encoder.layer.9.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "bert.encoder.layer.9.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "bert.encoder.layer.9.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.9.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.10.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.10.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.10.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "bert.encoder.layer.10.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "bert.encoder.layer.10.output.dense.weight\n",
      "torch.Size([768, 3072])\n",
      "bert.encoder.layer.10.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.10.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.query.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.query.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.key.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.key.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.11.attention.self.value.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.self.value.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.dense.weight\n",
      "torch.Size([768, 768])\n",
      "bert.encoder.layer.11.attention.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.11.intermediate.dense.weight\n",
      "torch.Size([3072, 768])\n",
      "bert.encoder.layer.11.intermediate.dense.bias\n",
      "torch.Size([3072])\n",
      "bert.encoder.layer.11.output.dense.weight\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([768, 3072])\n",
      "bert.encoder.layer.11.output.dense.bias\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.weight\n",
      "torch.Size([768])\n",
      "bert.encoder.layer.11.output.LayerNorm.bias\n",
      "torch.Size([768])\n",
      "bert.pooler.dense.weight\n",
      "torch.Size([768, 768])\n",
      "bert.pooler.dense.bias\n",
      "torch.Size([768])\n",
      "fc_bert.weight\n",
      "torch.Size([256, 768])\n",
      "fc_bert.bias\n",
      "torch.Size([256])\n",
      "baseline_in_FFN_BERT.publisher_embs.weight\n",
      "torch.Size([5, 100])\n",
      "baseline_in_FFN_BERT.fc1.weight\n",
      "torch.Size([256, 101])\n",
      "baseline_in_FFN_BERT.fc1.bias\n",
      "torch.Size([256])\n",
      "baseline_in_FFN_BERT.fc2.weight\n",
      "torch.Size([128, 256])\n",
      "baseline_in_FFN_BERT.fc2.bias\n",
      "torch.Size([128])\n",
      "baseline_in_FFN_BERT.fc3.weight\n",
      "torch.Size([64, 128])\n",
      "baseline_in_FFN_BERT.fc3.bias\n",
      "torch.Size([64])\n",
      "baseline_in_FFN_BERT.out.weight\n",
      "torch.Size([1, 64])\n",
      "baseline_in_FFN_BERT.out.bias\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for key in model.state_dict().keys():\n",
    "    print(key)\n",
    "    params = model.state_dict()[key]\n",
    "    print(params.size())\n",
    "    #print(params[0])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.state_dict().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_TRAINED_MODEL_NAME = 'bert-base-german-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-german-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-german-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = models.Bert_sequence(n_outputs=1)\n",
    "# this is exactly BertForSequenceClassifiaction (but just outputs logits)\n",
    "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shared columns: {'avgTimeOnPagePerWordcount', 'publisher', 'date', 'pagePath', 'category', 'dpaGuid', 'prozentVerlag', 'nr_tokens_text', 'zeilen', 'bounces', 'titel', 'entrances', 'exits', 'prozentDpa', 'rubric', 'timeOnPage', 'article_text', 'nr_tokens_publisher', 'avgTimeOnPage', 'pageviews', 'avgTimeOnPage_percentile', 'pageviews_percentile'}\n",
      "Shape of raw df: (97760, 22)\n"
     ]
    }
   ],
   "source": [
    "full = utils.get_raw_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>avgTimeOnPagePerWordcount</th>\n",
       "      <th>publisher</th>\n",
       "      <th>date</th>\n",
       "      <th>pagePath</th>\n",
       "      <th>category</th>\n",
       "      <th>dpaGuid</th>\n",
       "      <th>prozentVerlag</th>\n",
       "      <th>nr_tokens_text</th>\n",
       "      <th>zeilen</th>\n",
       "      <th>bounces</th>\n",
       "      <th>...</th>\n",
       "      <th>exits</th>\n",
       "      <th>prozentDpa</th>\n",
       "      <th>rubric</th>\n",
       "      <th>timeOnPage</th>\n",
       "      <th>article_text</th>\n",
       "      <th>nr_tokens_publisher</th>\n",
       "      <th>avgTimeOnPage</th>\n",
       "      <th>pageviews</th>\n",
       "      <th>avgTimeOnPage_percentile</th>\n",
       "      <th>pageviews_percentile</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>articleId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SZ_16591</th>\n",
       "      <td>0.088949</td>\n",
       "      <td>SZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sz-spezial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>535</td>\n",
       "      <td>NaN</td>\n",
       "      <td>76</td>\n",
       "      <td>...</td>\n",
       "      <td>1382</td>\n",
       "      <td>NaN</td>\n",
       "      <td>recht</td>\n",
       "      <td>48968.0</td>\n",
       "      <td>Coburg Sehr viele Eltern haben eine Vollmacht ...</td>\n",
       "      <td>535</td>\n",
       "      <td>47.587949</td>\n",
       "      <td>2411</td>\n",
       "      <td>56.993679</td>\n",
       "      <td>90.448376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SZ_16595</th>\n",
       "      <td>0.163308</td>\n",
       "      <td>SZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sz-spezial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>40</td>\n",
       "      <td>NaN</td>\n",
       "      <td>recht</td>\n",
       "      <td>2123.0</td>\n",
       "      <td>Berlin Das Verwaltungsgericht Berlin hat entsc...</td>\n",
       "      <td>250</td>\n",
       "      <td>40.826923</td>\n",
       "      <td>92</td>\n",
       "      <td>47.765865</td>\n",
       "      <td>3.960089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SZ_16723</th>\n",
       "      <td>0.166675</td>\n",
       "      <td>SZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sz-spezial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>26</td>\n",
       "      <td>...</td>\n",
       "      <td>308</td>\n",
       "      <td>NaN</td>\n",
       "      <td>recht</td>\n",
       "      <td>9972.0</td>\n",
       "      <td>Coburg Nicht jeder Rohrbruch ist versichert: B...</td>\n",
       "      <td>231</td>\n",
       "      <td>38.501931</td>\n",
       "      <td>567</td>\n",
       "      <td>43.811973</td>\n",
       "      <td>70.071579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SZ_17146</th>\n",
       "      <td>0.125154</td>\n",
       "      <td>SZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>magazine</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>785</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>momente</td>\n",
       "      <td>6386.0</td>\n",
       "      <td>Alfons Hewener heiratete erst spät. Wadgassen....</td>\n",
       "      <td>785</td>\n",
       "      <td>98.246154</td>\n",
       "      <td>101</td>\n",
       "      <td>84.367253</td>\n",
       "      <td>6.789167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SZ_17184</th>\n",
       "      <td>0.177933</td>\n",
       "      <td>SZ</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sz-spezial</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>398</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>124</td>\n",
       "      <td>NaN</td>\n",
       "      <td>recht</td>\n",
       "      <td>9702.0</td>\n",
       "      <td>München Ein Käufer kann erst dann von einem Ka...</td>\n",
       "      <td>398</td>\n",
       "      <td>70.817518</td>\n",
       "      <td>261</td>\n",
       "      <td>74.262519</td>\n",
       "      <td>49.028570</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           avgTimeOnPagePerWordcount publisher  date pagePath    category  \\\n",
       "articleId                                                                   \n",
       "SZ_16591                    0.088949        SZ   NaN      NaN  sz-spezial   \n",
       "SZ_16595                    0.163308        SZ   NaN      NaN  sz-spezial   \n",
       "SZ_16723                    0.166675        SZ   NaN      NaN  sz-spezial   \n",
       "SZ_17146                    0.125154        SZ   NaN      NaN    magazine   \n",
       "SZ_17184                    0.177933        SZ   NaN      NaN  sz-spezial   \n",
       "\n",
       "          dpaGuid  prozentVerlag  nr_tokens_text  zeilen  bounces  ... exits  \\\n",
       "articleId                                                          ...         \n",
       "SZ_16591      NaN            NaN             535     NaN       76  ...  1382   \n",
       "SZ_16595      NaN            NaN             250     NaN        6  ...    40   \n",
       "SZ_16723      NaN            NaN             231     NaN       26  ...   308   \n",
       "SZ_17146      NaN            NaN             785     NaN        1  ...    36   \n",
       "SZ_17184      NaN            NaN             398     NaN        9  ...   124   \n",
       "\n",
       "           prozentDpa   rubric  timeOnPage  \\\n",
       "articleId                                    \n",
       "SZ_16591          NaN    recht     48968.0   \n",
       "SZ_16595          NaN    recht      2123.0   \n",
       "SZ_16723          NaN    recht      9972.0   \n",
       "SZ_17146          NaN  momente      6386.0   \n",
       "SZ_17184          NaN    recht      9702.0   \n",
       "\n",
       "                                                article_text  \\\n",
       "articleId                                                      \n",
       "SZ_16591   Coburg Sehr viele Eltern haben eine Vollmacht ...   \n",
       "SZ_16595   Berlin Das Verwaltungsgericht Berlin hat entsc...   \n",
       "SZ_16723   Coburg Nicht jeder Rohrbruch ist versichert: B...   \n",
       "SZ_17146   Alfons Hewener heiratete erst spät. Wadgassen....   \n",
       "SZ_17184   München Ein Käufer kann erst dann von einem Ka...   \n",
       "\n",
       "           nr_tokens_publisher avgTimeOnPage  pageviews  \\\n",
       "articleId                                                 \n",
       "SZ_16591                   535     47.587949       2411   \n",
       "SZ_16595                   250     40.826923         92   \n",
       "SZ_16723                   231     38.501931        567   \n",
       "SZ_17146                   785     98.246154        101   \n",
       "SZ_17184                   398     70.817518        261   \n",
       "\n",
       "           avgTimeOnPage_percentile  pageviews_percentile  \n",
       "articleId                                                  \n",
       "SZ_16591                  56.993679             90.448376  \n",
       "SZ_16595                  47.765865              3.960089  \n",
       "SZ_16723                  43.811973             70.071579  \n",
       "SZ_17146                  84.367253              6.789167  \n",
       "SZ_17184                  74.262519             49.028570  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "785\n",
      "Alfons Hewener heiratete erst spät. Wadgassen. Alfons Hewener, Jahrgang 1952, wuchs in einem katholischen Elternhaus in Wadgassen in unmittelbarer Nachbarschaft der Wadgassener Kirche Maria Heimsuchung auf. Er ist der ältere von zwei Brüdern. Sein Vater war Stuckateurmeister, hatte einen eigenen Betrieb.Nach der Volksschule in Wadgassen wechselte er 1962 auf das Saarlouiser Gymnasium am Stadtgarten, ging jedoch da noch vor der Mittleren Reife ab. Er wollte Stuckateur, den Beruf seines Vaters, lernen. Das war ihm wichtig Er begann seine Lehre im elterlichen Betrieb, erzählt seine Frau Christa. Wir  seine Ehefrau Christa und Ruth Weiss, eine Freundin der Familie, die Alfons Hewener seit vielen Jahren kennt, und ich  sitzen in der ehemaligen Lagerhalle des elterlichen Stuckateurbetriebes, in der Alfons Hewener seinen Beruf erlernt und viele Jahre gearbeitet und die er zum ebenerdigen Wohnhaus umgebaut hat, und reden über das Leben eines ungewöhnlichen Mannes.Ruth Weiss beschreibt ihn als vielseitig interessierten, auch künstlerisch begabten Menschen. Seine Frau sagt: Wie sich später heraus stellen sollte, war das auch die absolut richtige Entscheidung. Es war handwerklich, auch künstlerisch begabt. Und Stuckateur  das war ein Beruf, der ihm Spaß machte und auch sein Leben prägen sollte.Nach drei Jahren Lehre machte er 1970 seine Gesellenprüfung vor der Handwerkskammer (Note: sehr gut) und im Leistungswettbewerb der Landesjugend der Stuckateure wurde er mit einer Urkunde als Bester ausgezeichnet. Im selben Jahr wurde die von dem weltberühmten spanischen Architekten Anton Gaudi 1882 erbaute Kirche ,Basilico de Sagrada\" (deutsch: Kirche der Heiligen Familie) in Barcelona restauriert und renoviert. Und der Preisträger des Wettbewerbs der Handwerkskammer durfte nach Barcelona fahren, um bei den anfallenden Stuckateurarbeiten zu helfen. Er hat nach der Rückkehr weiter im elterlichen Betrieb mitgearbeitet, musste dann aber als Wehrpflichtiger seinen Wehrdienst bei der Bundeswehr ableisten. Zurück in Wadgassen, arbeitete er weiter im elterlichen Betrieb. Er war ein sportlicher junger, groß gewachsener Kerl, spielte Tennis im Tennisverein Werbeln und auch Basketball im Basketballclub in Bous.1983 bestand er seine Meisterprüfung als Stuckateur, und im selben Jahr übernahm er von seinem Vater den elterlichen Betrieb. Und er war hilfsbereit, erzählt seine Frau Christa. Wenn jemand was brauchte, kam er zum Alfons. Er hatte viele Freunde. In seinem großen Freundeskreis galt er als eiserner Junggeselle.Das änderte sich 1991. Da lernte er in Essen, wo er seinen Freund Clemens besuchte, seine spätere Frau Christa im italienischen Restaurant Da Enrico kennen. Eine Freundin aus dem Saarland hatte das Treffen vermittelt. Ein halbes Jahr danach war erst mal Sendepause. Dann meldete er sich telefonisch, kündigte einen Besuch bei seinem Freund in Essen an, der seinen 40. Geburtstag feierte. Man traf sich wieder, und wieder... Und 1992 war es soweit: Die attraktive Blonde aus dem Ruhrpott, im Berufsleben in der Modebranche engagiert, zog ins Saarland zu Alfons. Am 13. 12. 1993 war die Hochzeit. Der eiserne Junggeselle sagte Ja!. Die Braut brachte Patrick, ihren inzwischen erwachsenen Sohn, mit in die Ehe. Patrick und der Stiefvater verstanden sich künftig prächtig.Und er änderte auch sein Leben. Er war bisher nicht richtig in Urlaub gewesen. Jetzt fuhr das Paar nach Ibiza und nach Südfrankreich. Und künftig verbrachten sie die Wochenenden am Stockweiher, in Rhodes. Erst in einem Wohnwagen, dann in einem gemieteten Häuschen. Er hatte inzwischen Segeln gelernt und auch den Sportbootführerschein erworben und sich eine kleine Segelyacht gekauft.Am 5. Februar 2010 diagnostizierten Ärzte der Uni-Klinik Homburg nach einer gründlichen Untersuchung Verdacht auf einen Gehirntumor.\" Bei einer weiteren Untersuchung stellten sie fest: Metastasen im Kopf und ein Karzinom in der Lunge. Seine Frau sagt: Er hoffte, das das alles behandelbar ist. Er war optimistisch. Zu seiner Frau sagte er, als sie über die Diagnose redeten: Mach nicht so ein Gesicht. Stell Dir vor, es wäre etwas Ernstes. Als sich abzeichnete, dass er die Krankheit nicht besiegen würde, holte ich ihn nach Hause. Er lag im Wohnzimmer. Als seine Freunde ihn besuchten, sagte er: Ich bin froh, dass ihr da seid. Dann ist die Christa einmal nicht allein . Regelmäßigen Besuch bekam er von unserem sehr liebenswerten Pastor Teklik. Mein Mann freute sich immer ihn zu sehen. Er versah ihn auch mit der Krankensalbung und den heiligen Sakramenten. Als er starb, saß ich neben ihm. Er war die Liebe meines Lebens.Rund 200 Trauergesäte gaben Alfons Hewener bei seiner Beerdigung auf dem Abteifriedhof in Wadgassen das letzte Geleit. Sein Bruder Herbert sagte am Grab: Alfons war ein ewiger Optimist, so gelassen und menschenfreundlich wie kaum jemand, den ich je kennen gelernt habe. Er hat sich nicht einfach im Leben aufgehalten, denn er hatte das Talent, sein Leben auch als Dolce Vita zu genießen. Wenn wir jetzt beim Abschied auch trauern, sollten wir uns doch dankbar an das erinnern, was sein Leben ausmachte und unser Leben mit ihm: Es waren wunderschöne Zeiten.\n"
     ]
    }
   ],
   "source": [
    "#ID = \"SZ_16595\"\n",
    "ID = \"SZ_17146\"\n",
    "text = full.loc[ID, \"article_text\"]\n",
    "print(full.loc[ID, \"nr_tokens_text\"])\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding = tokenizer.encode_plus(text,\n",
    "                                      max_length=None,\n",
    "                                      truncation=True,\n",
    "                                      return_token_type_ids=False,\n",
    "                                      pad_to_max_length=False,\n",
    "                                      return_attention_mask=True,\n",
    "                                      return_tensors='pt',\n",
    "                                      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = encoding['input_ids'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "512"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    3, 26401,  1873,  4012,     6,  5409,   624,  7451, 26914,  3221,\n",
       "        26904, 12393, 26898, 26914, 26401,  1873,  4012,     6, 26918, 10047,\n",
       "         6470, 26918,  6530,    50,   297,  8322,  2579,   691,    50,  3221,\n",
       "        26904, 12393, 26898,    50, 14551, 16177,    21,  3221, 26904, 12393,\n",
       "          344,  1698,  4281,  2104, 13736,   115, 26914,   177,   127,    21,\n",
       "        10422,    88,   382, 21296, 26914,  2148,  2230,   185, 21956,   962,\n",
       "         2914,   647, 26918,   466,   303,  1931,  1288, 26914,   326,    21,\n",
       "        17614,    50,  3221, 26904, 12393, 26898,  3015,    67,  6363,   115,\n",
       "           93,  8089,   563, 18145,   251,  7730,   235,   560,  5579, 26918,\n",
       "         1866,   742,   348,   357,   200,    21, 25357, 21394,   281, 26914,\n",
       "            2,  2664, 21956,   962,    37, 26918,    86,  1127,  1688,  7064,\n",
       "        26918, 10881, 26914,   295,   185,   787,  2945,   177,  1765,   498,\n",
       "         8364,   106, 23370,   248,     2, 26918,  5429,   498,   946,  1690,\n",
       "        26903, 26914,   655,     2,   498,  5542,  1690, 26903,    42, 21920,\n",
       "        22771, 26918,   155,  9742,    21,  1786, 26918,    30, 26401,  1873,\n",
       "         4012,     6,   602,  2709,   605,  7885, 26918,    42,  1169,     2,\n",
       "         8532,    50,    21,  3170,  4458,  5296,    91, 23370,   248, 21956,\n",
       "          962, 16030,    75,  4859, 26902, 26918,    50,    21, 26401,  1873,\n",
       "         4012,     6,   800,  1127, 15313, 26901,    42,  1480,   573,  8650,\n",
       "           42,    30,    67,   260,   914,     6,  5730, 13083, 11749,   193,\n",
       "        26918,    42, 11614,   204,    93,   826,   443, 23479, 26898, 10794,\n",
       "        26914, 21920, 22771,  8219,   716,   153,     2, 23262, 26898, 26918,\n",
       "          194,  7258,    85, 18374,    47,  1075, 26914,     2,  2072,   946,\n",
       "         1462, 26964,     2,   144,   878,  1946,  3392,  1547, 26918,   185,\n",
       "           93,   194,    30, 15595, 11770,  1410, 26914,   482,   185, 26411,\n",
       "           68, 26918,   194,  7258,    85, 18374, 26901, 26914,  1356, 21956,\n",
       "          962,    37,     2,    93,   185,    39,  1127, 26918,    21,   787,\n",
       "        11460,  3054,    42,   194,   167,   826, 24876,  1547, 26914,     2,\n",
       "          678,   605,  8364,  3054,    67,  3493,   498,  4997,     7,  4505,\n",
       "          200,    21, 21203,  5276, 26954, 17834, 26964,     2,     2, 26955,\n",
       "           42,   106,  3858, 10407,    21,  1168, 19775,    21, 21956,   962,\n",
       "         2401,   192,    67,   114,   225, 12278,   153, 21888,  5400, 26914,\n",
       "          346,  4469,   203,   192,    30,    88,   128,  3522,    73, 12684,\n",
       "            7,  8467,  6955,  5056,  9016,  3748, 15398, 17466,  1698, 26918,\n",
       "            2,   900,   773,  6969, 26903, 26944, 26954,   635, 26964,  1698,\n",
       "           21,  6999,  1786, 26955,    50, 10408, 18277,    42, 20252, 26914,\n",
       "         1356,    21, 22639,    91, 11069,    21, 21203,  5276,  7392,   188,\n",
       "        10408,  7452, 26918,   259,   178,    86,  9300,  2700,    65, 21956,\n",
       "          962,  7065, 26900,  5312,     7,    81,  7336, 26914,   177,   193,\n",
       "          188,    21,  5268,   424,   106, 23370,   248,  1288,  6939,  3628,\n",
       "        26918,  2168,   670,   386,   153,  5329, 14829, 26900,   800, 22469,\n",
       "          178,    21,  6407, 11635,   828, 26914,  7740,    50,  3221, 26904,\n",
       "        12393, 26898, 26918,  2525,    67,   424,   106, 23370,   248,  1288,\n",
       "        26914,   177,   185,    39, 19787, 26900, 13194, 26918,  1693, 13963,\n",
       "            6,  5967, 26907, 26918,  2193,  9266,   106,  9266,  3283,  8645,\n",
       "        26907, 26898,    42,   194,  9775,   106,  9775, 14413,    50,  1035,\n",
       "           51, 26914,  5613,  3445,    67,   498,  2318,  4505,   153, 21956,\n",
       "          962,    37, 26918,    42,   106,  4469,   203,  3126,    67,    88,\n",
       "          813,  2230,    86, 23370,   248,  1288, 26914,     2,    67,   185,\n",
       "            2, 26918,  5429,   498,   946,  1690, 26903, 26914,     2,  8026,\n",
       "          961, 22025, 26918,  1125,    67,   260, 26401, 26914,   177,   466,\n",
       "         1480,     4])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = tokenizer.tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1116"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alfons / He / ##wen / ##er / heiratete / erst / spät / . / Wa / ##d / ##gasse / ##n / . / Alfons / He / ##wen / ##er / , / Jahrgang / 1952 / , / wuchs / in / einem / katholischen / Eltern / ##haus / in / Wa / ##d / ##gasse / ##n / in / unmittelbarer / Nachbarschaft / der / Wa / ##d / ##gasse / ##ner / Kirche / Maria / Heim / ##suchung / auf / . / Er / ist / der / ältere / von / zwei / Brüdern / . / Sein / Vater / war / Stuck / ##ate / ##urm / ##eister / , / hatte / einen / eigenen / Betrieb / . / Nach / der / Volksschule / in / Wa / ##d / ##gasse / ##n / wechselte / er / 1962 / auf / das / Saar / ##lo / ##ui / ##ser / Gymnasium / am / Stadt / ##garten / , / ging / jedoch / da / noch / vor / der / Mittleren / Reife / ab / . / [UNK] / wollte / Stuck / ##ate / ##ur / , / den / Beruf / seines / Vaters / , / lernen / . / Das / war / ihm / wichtig / Er / begann / seine / Lehre / im / elter / ##lichen / [UNK] / , / erzählt / seine / Frau / Christ / ##a / . / Wir / [UNK] / seine / Ehefrau / Christ / ##a / und / Ruth / Weiss / , / eine / Freundin / der / Familie / , / die / Alfons / He / ##wen / ##er / seit / vielen / Jahren / kennt / , / und / ich / [UNK] / sitzen / in / der / ehemaligen / Lager / ##halle / des / elter / ##lichen / Stuck / ##ate / ##urb / ##et / ##riebe / ##s / , / in / der / Alfons / He / ##wen / ##er / seinen / Beruf / erlern / ##t / und / viele / Jahre / gearbeitet / und / die / er / zum / eben / ##er / ##digen / Wohnhaus / umgebaut / hat / , / und / reden / über / das / Leben / eines / ungewöhnliche / ##n / Mannes / . / Ruth / Weiss / beschreibt / ihn / als / [UNK] / interessierte / ##n / , / auch / künstler / ##isch / begab / ##ten / Menschen / . / [UNK] / Seine / Frau / sagt / : / [UNK] / sich / später / heraus / stellen / sollte / , / war / das / auch / die / absolut / richtige / Entscheidung / . / Es / war / handwerk / ##lich / , / auch / künstler / ##isch / begab / ##t / . / Und / Stuck / ##ate / ##ur / [UNK] / das / war / ein / Beruf / , / der / ihm / Spaß / machte / und / auch / sein / Leben / prägen / sollte / . / [UNK] / drei / Jahren / Lehre / machte / er / 1970 / seine / Gesell / ##en / ##prüfung / vor / der / Handwerks / ##kammer / ( / Note / : / [UNK] / [UNK] / ) / und / im / Leistungs / ##wettbewerb / der / Landes / ##jugend / der / Stuck / ##ate / ##ure / wurde / er / mit / einer / Urkunde / als / Bester / ausgezeichnet / . / Im / selben / Jahr / wurde / die / von / dem / welt / ##ber / ##ühmt / ##en / spanischen / Architekten / Anton / Gau / ##di / 1882 / erbaute / Kirche / , / [UNK] / de / Sa / ##grad / ##a / \" / ( / deutsch / : / Kirche / der / Heiligen / Familie / ) / in / Barcelona / restauriert / und / renoviert / . / Und / der / Preisträger / des / Wettbewerbs / der / Handwerks / ##kammer / durfte / nach / Barcelona / fahren / , / um / bei / den / anf / ##allen / ##den / Stuck / ##ate / ##ura / ##r / ##beit / ##en / zu / helfen / . / Er / hat / nach / der / Rückkehr / weiter / im / elter / ##lichen / Betrieb / mitge / ##arbeitet / , / musste / dann / aber / als / Wehr / ##pflichtige / ##r / seinen / Wehrdienst / bei / der / Bundeswehr / able / ##isten / . / Zurück / in / Wa / ##d / ##gasse / ##n / , / arbeitete / er / weiter / im / elter / ##lichen / Betrieb / . / Er / war / ein / sportliche / ##r / junger / , / groß / gewachsen / ##er / Ker / ##l / , / spielte / Tennis / im / Tennis / ##verein / Werbe / ##l / ##n / und / auch / Basketball / im / Basketball / ##club / in / Bo / ##us / . / 1983 / bestand / er / seine / Meister / ##prüfung / als / Stuck / ##ate / ##ur / , / und / im / selben / Jahr / übernahm / er / von / seinem / Vater / den / elter / ##lichen / Betrieb / . / [UNK] / er / war / [UNK] / , / erzählt / seine / Frau / Christ / ##a / . / [UNK] / jemand / was / brauchte / , / kam / er / zum / Alfons / . / Er / hatte / viele / Freunde / .'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" / \".join(tokens[:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# das ist ungefähr die Hälft des Textes, also so ca. 390 Tokens in meiner nr_tokens_text-Zählung\n",
    "# (die glaube ich ohne Satzzeichen ist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392.5"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "785/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
